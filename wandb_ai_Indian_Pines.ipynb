{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "wandb.ai Indian Pines.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucalyptus/wandb-experiments/blob/master/wandb_ai_Indian_Pines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_4zp39jlKPb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "247b34a6-6329-4e5d-d492-1373b5871bc2"
      },
      "source": [
        "# WandB – Install the W&B library\n",
        "!pip install wandb -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.4MB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 9.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 17.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 9.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 17.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.8MB/s \n",
            "\u001b[?25h  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGjKvdeCcTBl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "6657a309-dcb3-4f9f-b2db-5d276e2b6b32"
      },
      "source": [
        "!pip install kornia==0.2.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kornia==0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/b8/c137c3d0cc52a856d3f80ccc37281cc558df8c0b6b5f54d4cd78f4c3fb99/kornia-0.2.0-py2.py3-none-any.whl (142kB)\n",
            "\r\u001b[K     |██▎                             | 10kB 22.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from kornia==0.2.0) (7.0.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from kornia==0.2.0) (1.5.1+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->kornia==0.2.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->kornia==0.2.0) (1.18.5)\n",
            "Installing collected packages: kornia\n",
            "Successfully installed kornia-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzHnpxXzlPEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import random # to set the python random seed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aySwtTTLdACS",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import os\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from scipy import io \n",
        "import torch.utils.data\n",
        "import scipy\n",
        "from scipy.stats import entropy\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Ignore excessive warnings\n",
        "import logging\n",
        "logging.propagate = False \n",
        "logging.getLogger().setLevel(logging.ERROR)\n",
        "\n",
        "# WandB – Import the wandb library\n",
        "import wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O_vZ-V7Cfffp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "dd701307-4b45-464c-dd96-d4a2d0e837bd"
      },
      "source": [
        "!pip install -U spectral\n",
        "\n",
        "\n",
        "if not (os.path.isfile('/content/Indian_pines_corrected.mat')):\n",
        "  !wget http://www.ehu.eus/ccwintco/uploads/6/67/Indian_pines_corrected.mat\n",
        "if not (os.path.isfile('/content/Indian_pines_gt.mat')):\n",
        "  !wget http://www.ehu.eus/ccwintco/uploads/c/c4/Indian_pines_gt.mat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spectral\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/ff/f6e238a941ed55079526996fee315fbee5167aaa64de3e64980637ac8f38/spectral-0.21-py3-none-any.whl (187kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 28.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from spectral) (1.18.5)\n",
            "Installing collected packages: spectral\n",
            "Successfully installed spectral-0.21\n",
            "--2020-07-15 06:29:40--  http://www.ehu.eus/ccwintco/uploads/6/67/Indian_pines_corrected.mat\n",
            "Resolving www.ehu.eus (www.ehu.eus)... 158.227.0.65, 2001:720:1410::65\n",
            "Connecting to www.ehu.eus (www.ehu.eus)|158.227.0.65|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5953527 (5.7M) [text/plain]\n",
            "Saving to: ‘Indian_pines_corrected.mat’\n",
            "\n",
            "Indian_pines_correc 100%[===================>]   5.68M   342KB/s    in 19s     \n",
            "\n",
            "2020-07-15 06:30:01 (305 KB/s) - ‘Indian_pines_corrected.mat’ saved [5953527/5953527]\n",
            "\n",
            "--2020-07-15 06:30:05--  http://www.ehu.eus/ccwintco/uploads/c/c4/Indian_pines_gt.mat\n",
            "Resolving www.ehu.eus (www.ehu.eus)... 158.227.0.65, 2001:720:1410::65\n",
            "Connecting to www.ehu.eus (www.ehu.eus)|158.227.0.65|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1125 (1.1K) [text/plain]\n",
            "Saving to: ‘Indian_pines_gt.mat’\n",
            "\n",
            "Indian_pines_gt.mat 100%[===================>]   1.10K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-07-15 06:30:05 (230 MB/s) - ‘Indian_pines_gt.mat’ saved [1125/1125]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8Ap1zqDEf5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn import Module, Sequential, Conv2d, ReLU,AdaptiveMaxPool2d, AdaptiveAvgPool2d, \\\n",
        "    NLLLoss, BCELoss, CrossEntropyLoss, AvgPool2d, MaxPool2d, Parameter, Linear, Sigmoid, Softmax, Dropout, Embedding\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJsicKsKmYcB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "54d8a139-f646-4b89-daf7-093eb114e5b2"
      },
      "source": [
        "# WandB – Login to your wandb account so you can log all your metrics\n",
        "!wandb login"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://app.wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://app.wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: c30ac8a9c1d4811a005d8142d26b7352c536db10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBVkmtpxduGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io as sio\n",
        "def loadData():\n",
        "    data = sio.loadmat('Indian_pines_corrected.mat')['indian_pines_corrected']\n",
        "    labels = sio.loadmat('Indian_pines_gt.mat')['indian_pines_gt']\n",
        "    \n",
        "    return data, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pjCQsohnvrEF",
        "colab": {}
      },
      "source": [
        "def padWithZeros(X, margin=2):\n",
        "\n",
        "    ## From: https://github.com/gokriznastic/HybridSN/blob/master/Hybrid-Spectral-Net.ipynb\n",
        "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
        "    x_offset = margin\n",
        "    y_offset = margin\n",
        "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
        "    return newX\n",
        "\n",
        "def createImageCubes(X, y, windowSize=5, removeZeroLabels = True):\n",
        "\n",
        "     ## From: https://github.com/gokriznastic/HybridSN/blob/master/Hybrid-Spectral-Net.ipynb\n",
        "    margin = int((windowSize - 1) / 2)\n",
        "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
        "    # split patches\n",
        "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]), dtype=np.uint8)\n",
        "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]), dtype=np.uint8)\n",
        "    patchIndex = 0\n",
        "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
        "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
        "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n",
        "            patchesData[patchIndex, :, :, :] = patch\n",
        "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
        "            patchIndex = patchIndex + 1\n",
        "    if removeZeroLabels:\n",
        "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
        "        patchesLabels = patchesLabels[patchesLabels>0]\n",
        "        patchesLabels -= 1\n",
        "    return patchesData, patchesLabels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sYgdv3VZw2mz",
        "colab": {}
      },
      "source": [
        "class HyperSpectralDataset(Dataset):\n",
        "    \"\"\"HyperSpectral dataset.\"\"\"\n",
        "\n",
        "    def __init__(self,data_url,label_url,windowsize=7):\n",
        "        self.windowsize=windowsize\n",
        "        self.data = np.array(scipy.io.loadmat('/content/'+data_url.split('/')[-1])[data_url.split('/')[-1].split('.')[0].lower()])\n",
        "        self.targets = np.array(scipy.io.loadmat('/content/'+label_url.split('/')[-1])[label_url.split('/')[-1].split('.')[0].lower()])\n",
        "        self.data, self.targets = createImageCubes(self.data,self.targets, windowSize=self.windowsize)\n",
        "        \n",
        "        \n",
        "        self.data = torch.Tensor(self.data)\n",
        "        self.data = self.data.permute(0,3,1,2)\n",
        "        print(self.data.shape)\n",
        "        print(self.targets.shape)\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "      \n",
        "      return self.data[idx,:,:,:] , self.targets[idx]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSUClIp6HZs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hyperparameter_defaults = dict(\n",
        "    batch_size = 16,\n",
        "    learning_rate = 0.01,\n",
        "    momentum=0.9,\n",
        "    epochs = 50,\n",
        "    top=25,\n",
        "    windowsize=7,\n",
        "    bands=200,\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpLrORrqJKa3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6dc1867b-47ad-4f6a-cb66-4ac0dac55af3"
      },
      "source": [
        "wandb.init(config=hyperparameter_defaults,project=\"indian-pines\")\n",
        "config = wandb.config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/ucalyptus/indian-pines\" target=\"_blank\">https://app.wandb.ai/ucalyptus/indian-pines</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/ucalyptus/indian-pines/runs/1m341jrp\" target=\"_blank\">https://app.wandb.ai/ucalyptus/indian-pines/runs/1m341jrp</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TJY-1XbQbb64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "963c7258-4999-491b-f0fb-3b743b94b9be"
      },
      "source": [
        "data_train = HyperSpectralDataset('Indian_pines_corrected.mat','Indian_pines_gt.mat',config.windowsize)\n",
        "\n",
        "train_loader = DataLoader(data_train, batch_size=config.batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10249, 200, 7, 7])\n",
            "(10249,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywDLKnyY1E1F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b57d36d4-ee7d-4ff8-a42f-f615b503afee"
      },
      "source": [
        "print(data_train.__getitem__(0)[0].shape)\n",
        "print(data_train.__len__())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([200, 7, 7])\n",
            "10249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUeiQr1GFgCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PAM_Module(Module):\n",
        "    \"\"\" Position attention module  https://github.com/junfu1115/DANet/blob/master/encoding/nn/attention.py\"\"\"\n",
        "    #Ref from SAGAN\n",
        "    def __init__(self, in_dim):\n",
        "        super(PAM_Module, self).__init__()\n",
        "        self.chanel_in = in_dim\n",
        "\n",
        "        self.query_conv = Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
        "        self.key_conv = Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
        "        self.value_conv = Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n",
        "        \n",
        "        self.gamma = Parameter(torch.zeros(1))\n",
        "\n",
        "        self.softmax = Softmax(dim=-1)\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "            inputs :\n",
        "                x : input feature maps( B X C X H X W)\n",
        "            returns :\n",
        "                out : attention value + input feature\n",
        "                attention: B X (HxW) X (HxW)\n",
        "        \"\"\"\n",
        "        m_batchsize, C, height, width = x.size()\n",
        "        proj_query = self.query_conv(x).view(m_batchsize, -1, width*height).permute(0, 2, 1)\n",
        "        proj_key = self.key_conv(x).view(m_batchsize, -1, width*height)\n",
        "        energy = torch.bmm(proj_query, proj_key)\n",
        "        attention = self.softmax(energy)\n",
        "        proj_value = self.value_conv(x).view(m_batchsize, -1, width*height)\n",
        "\n",
        "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
        "        out = out.view(m_batchsize, C, height, width)\n",
        "\n",
        "        out = self.gamma*out + x\n",
        "        #out = F.avg_pool2d(out, out.size()[2:4])\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "class CAM_Module(Module):\n",
        "    \"\"\" Channel attention module https://github.com/junfu1115/DANet/blob/master/encoding/nn/attention.py\"\"\"\n",
        "    def __init__(self):\n",
        "        super(CAM_Module, self).__init__()\n",
        "        #self.chanel_in = in_dim\n",
        "        \n",
        "        \n",
        "\n",
        "\n",
        "        self.gamma = Parameter(torch.zeros(1))\n",
        "        self.softmax  = Softmax(dim=-1)\n",
        "    def forward(self,x):\n",
        "        \"\"\"\n",
        "            inputs :\n",
        "                x : input feature maps( B X C X H X W)\n",
        "            returns :\n",
        "                out : attention value + input feature\n",
        "                attention: B X C X C\n",
        "        \"\"\"\n",
        "        m_batchsize, C, height, width = x.size()\n",
        "        proj_query = x.view(m_batchsize, C, -1)\n",
        "        proj_key = x.view(m_batchsize, C, -1).permute(0, 2, 1)\n",
        "        energy = torch.bmm(proj_query, proj_key)\n",
        "        energy_new = torch.max(energy, -1, keepdim=True)[0].expand_as(energy)-energy\n",
        "        attention = self.softmax(energy_new)\n",
        "        proj_value = x.view(m_batchsize, C, -1)\n",
        "\n",
        "        out = torch.bmm(attention, proj_value)\n",
        "        out = out.view(m_batchsize, C, height, width)\n",
        "\n",
        "        out = self.gamma*out + x\n",
        "        #out = F.avg_pool2d(out, out.size()[2:4])\n",
        "        #out = self.last_conv(out)\n",
        "        \n",
        "        \n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q47qdlizX9EY",
        "colab": {}
      },
      "source": [
        "class RecNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RecNet, self).__init__()\n",
        "        self.conv3d_1 = nn.Sequential(nn.Conv3d(1, 128, (1, 3, 3), 1), \n",
        "                        nn.BatchNorm3d(128),\n",
        "                        nn.PReLU())\n",
        "        \n",
        "        self.conv3d_2 = nn.Sequential(nn.Conv3d(128, 64, (1, 3, 3), 1),\n",
        "                        nn.BatchNorm3d(64),\n",
        "                        nn.PReLU())\n",
        "                        \n",
        "        \n",
        "        self.pool3d = nn.MaxPool3d((1, 1, 1), (1, 1, 1))\n",
        "        \n",
        "        self.deconv3d_1 = nn.Sequential(nn.ConvTranspose3d(64, 128, (1, 3, 3), 1),\n",
        "                          nn.BatchNorm3d(128),\n",
        "                          nn.PReLU())\n",
        "        \n",
        "        self.deconv3d_2 = nn.Sequential(nn.ConvTranspose3d(128, 1, (1, 3, 3), 1),\n",
        "                          nn.BatchNorm3d(1))\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv3d_1(x)\n",
        "        x = self.conv3d_2(x)\n",
        "        \n",
        "        x = self.pool3d(x)\n",
        "        \n",
        "        x = self.deconv3d_1(x)\n",
        "        x = self.deconv3d_2(x)\n",
        "        \n",
        "        \n",
        "        return x.squeeze(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8VpTQM2ot7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DANet(Module):\n",
        "  def __init__(self):\n",
        "    super(DANet,self).__init__()\n",
        "    self.PAM_Module = PAM_Module(config.bands)\n",
        "    self.CAM_Module = CAM_Module()\n",
        "    self.RecNet = RecNet()\n",
        "  def forward(self,x):\n",
        "    \n",
        "    P = self.PAM_Module(x)\n",
        "    C = self.CAM_Module(x)\n",
        "    #B,Ch,H,W = P.size()\n",
        "    J = P + C\n",
        "    J =  J.unsqueeze(1)\n",
        "    ret = self.RecNet(J)\n",
        "    \n",
        "    \n",
        "    \n",
        "    return ret\n",
        "    \n",
        "    \n",
        "danet_model = DANet().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqSJNhGNCUHJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "c258b5bc-ea6a-4cdc-f909-bf014c2dbef0"
      },
      "source": [
        "\n",
        "from torchsummary import summary\n",
        "summary(danet_model,input_size=(config.bands,config.windowsize,config.windowsize))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1             [-1, 25, 7, 7]           5,025\n",
            "            Conv2d-2             [-1, 25, 7, 7]           5,025\n",
            "           Softmax-3               [-1, 49, 49]               0\n",
            "            Conv2d-4            [-1, 200, 7, 7]          40,200\n",
            "        PAM_Module-5            [-1, 200, 7, 7]               0\n",
            "           Softmax-6             [-1, 200, 200]               0\n",
            "        CAM_Module-7            [-1, 200, 7, 7]               0\n",
            "            Conv3d-8       [-1, 128, 200, 5, 5]           1,280\n",
            "       BatchNorm3d-9       [-1, 128, 200, 5, 5]             256\n",
            "            PReLU-10       [-1, 128, 200, 5, 5]               1\n",
            "           Conv3d-11        [-1, 64, 200, 3, 3]          73,792\n",
            "      BatchNorm3d-12        [-1, 64, 200, 3, 3]             128\n",
            "            PReLU-13        [-1, 64, 200, 3, 3]               1\n",
            "        MaxPool3d-14        [-1, 64, 200, 3, 3]               0\n",
            "  ConvTranspose3d-15       [-1, 128, 200, 5, 5]          73,856\n",
            "      BatchNorm3d-16       [-1, 128, 200, 5, 5]             256\n",
            "            PReLU-17       [-1, 128, 200, 5, 5]               1\n",
            "  ConvTranspose3d-18         [-1, 1, 200, 7, 7]           1,153\n",
            "      BatchNorm3d-19         [-1, 1, 200, 7, 7]               2\n",
            "           RecNet-20            [-1, 200, 7, 7]               0\n",
            "================================================================\n",
            "Total params: 200,976\n",
            "Trainable params: 200,976\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.04\n",
            "Forward/backward pass size (MB): 33.60\n",
            "Params size (MB): 0.77\n",
            "Estimated Total Size (MB): 34.41\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_UVWhGROX9Ei",
        "colab": {}
      },
      "source": [
        "\n",
        "optimizer = optim.SGD(danet_model.parameters(), lr=config.learning_rate, momentum=config.momentum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXu9YPFIzJm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top = config.top"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mFUiHpJyX9Em",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b27a4b3-1f08-468c-d7ff-232eefe6fe91"
      },
      "source": [
        "\n",
        "\n",
        "import skimage\n",
        "import kornia\n",
        "global bsnlist\n",
        "ssim = kornia.losses.SSIM(5, reduction='none')\n",
        "psnr = kornia.losses.PSNRLoss(2500)\n",
        "from skimage import measure\n",
        "ssim_list = []\n",
        "psnr_list = []\n",
        "l1_list = []\n",
        "channel_weight_list = []\n",
        "def train(epoch):    \n",
        "    danet_model.train()\n",
        "    ENTROPY = torch.zeros(config.bands)\n",
        "    \n",
        "    for batch_idx, (data, __) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = danet_model(data)\n",
        "        loss = F.l1_loss(output,data)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        D = output.detach().cpu().numpy()\n",
        "        for i in range(0,config.bands):\n",
        "\n",
        "          ENTROPY[i]+=skimage.measure.shannon_entropy(D[:,i,:,:])\n",
        "        \n",
        "        if batch_idx % (0.5*len(train_loader)) == 0:\n",
        "\n",
        "\n",
        "\n",
        "            L1 = loss.item()\n",
        "            wandb.log({\"loss\":L1})\n",
        "            l1_list.append(L1)\n",
        "            ssim_val = torch.mean(ssim(data,output))\n",
        "            wandb.log({\"SSIM\":1.-ssim_val})\n",
        "            ssim_list.append(1.-ssim_val)\n",
        "            psnr_val = psnr(data,output)\n",
        "            wandb.log({\"PSNR\":psnr_val})\n",
        "            psnr_list.append(psnr_val)\n",
        "        \n",
        "        \n",
        "    ENTROPY = np.array(ENTROPY)\n",
        "    bsnlist = np.asarray(ENTROPY.argsort()[-top:][::-1])\n",
        "    print('Top {} bands with Entropy ->'.format(top),list(bsnlist))\n",
        "    \n",
        "    \n",
        "\n",
        "wandb.watch(danet_model)\n",
        "for epoch in range(0, config.epochs):\n",
        "    train(epoch)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 25 bands with Entropy -> [103, 143, 144, 197, 1, 195, 145, 104, 89, 196, 198, 149, 52, 51, 31, 35, 119, 53, 49, 176, 125, 27, 156, 46, 137]\n",
            "Top 25 bands with Entropy -> [104, 109, 102, 148, 143, 105, 195, 170, 175, 141, 194, 196, 176, 174, 157, 149, 173, 156, 103, 192, 197, 80, 136, 77, 2]\n",
            "Top 25 bands with Entropy -> [167, 17, 113, 2, 46, 190, 69, 157, 18, 101, 141, 64, 92, 133, 173, 49, 59, 153, 21, 136, 77, 171, 44, 11, 75]\n",
            "Top 25 bands with Entropy -> [113, 60, 24, 57, 169, 136, 34, 96, 46, 90, 188, 38, 118, 28, 87, 58, 77, 22, 54, 52, 2, 85, 63, 17, 20]\n",
            "Top 25 bands with Entropy -> [11, 22, 47, 99, 92, 8, 26, 29, 15, 12, 13, 42, 61, 79, 135, 174, 33, 30, 86, 81, 66, 37, 53, 21, 157]\n",
            "Top 25 bands with Entropy -> [162, 131, 50, 132, 113, 29, 92, 83, 125, 172, 99, 7, 58, 66, 45, 27, 22, 129, 114, 54, 56, 166, 20, 72, 23]\n",
            "Top 25 bands with Entropy -> [11, 72, 93, 80, 52, 19, 157, 35, 43, 29, 56, 55, 67, 161, 131, 84, 86, 90, 109, 117, 22, 36, 32, 137, 59]\n",
            "Top 25 bands with Entropy -> [26, 29, 98, 18, 3, 86, 115, 77, 79, 114, 38, 45, 37, 19, 24, 60, 171, 28, 95, 7, 108, 96, 16, 14, 35]\n",
            "Top 25 bands with Entropy -> [118, 114, 63, 99, 59, 90, 89, 50, 161, 12, 52, 24, 123, 40, 13, 174, 48, 84, 141, 34, 96, 95, 91, 78, 160]\n",
            "Top 25 bands with Entropy -> [127, 121, 82, 65, 5, 20, 55, 78, 66, 17, 91, 135, 14, 154, 90, 97, 88, 32, 116, 27, 56, 75, 125, 45, 114]\n",
            "Top 25 bands with Entropy -> [27, 42, 50, 99, 12, 40, 17, 58, 59, 118, 89, 80, 28, 35, 13, 15, 45, 64, 66, 36, 46, 26, 134, 48, 21]\n",
            "Top 25 bands with Entropy -> [32, 96, 49, 42, 135, 67, 68, 122, 54, 92, 93, 154, 87, 11, 75, 61, 60, 31, 124, 59, 74, 83, 168, 46, 90]\n",
            "Top 25 bands with Entropy -> [28, 41, 138, 136, 160, 78, 135, 43, 153, 82, 166, 46, 14, 91, 32, 25, 27, 131, 95, 59, 19, 77, 2, 67, 37]\n",
            "Top 25 bands with Entropy -> [65, 170, 99, 113, 45, 62, 164, 55, 77, 14, 86, 5, 82, 81, 11, 27, 34, 129, 119, 116, 56, 70, 73, 71, 41]\n",
            "Top 25 bands with Entropy -> [71, 136, 3, 47, 24, 27, 130, 28, 113, 75, 49, 167, 74, 38, 173, 122, 37, 36, 20, 6, 18, 154, 176, 73, 124]\n",
            "Top 25 bands with Entropy -> [158, 164, 52, 98, 97, 113, 87, 86, 83, 35, 77, 67, 154, 4, 92, 29, 3, 30, 121, 47, 49, 135, 170, 61, 70]\n",
            "Top 25 bands with Entropy -> [98, 68, 8, 65, 38, 53, 59, 92, 75, 118, 44, 26, 85, 89, 35, 96, 24, 86, 93, 32, 60, 40, 20, 77, 113]\n",
            "Top 25 bands with Entropy -> [115, 18, 47, 29, 72, 118, 172, 52, 80, 25, 38, 66, 40, 30, 24, 122, 53, 19, 132, 87, 83, 92, 27, 35, 32]\n",
            "Top 25 bands with Entropy -> [39, 61, 129, 98, 166, 60, 46, 73, 10, 95, 23, 70, 17, 127, 113, 64, 37, 48, 42, 71, 93, 162, 67, 94, 83]\n",
            "Top 25 bands with Entropy -> [57, 47, 54, 5, 46, 43, 137, 59, 80, 23, 21, 68, 36, 45, 112, 7, 122, 37, 130, 34, 17, 12, 56, 50, 121]\n",
            "Top 25 bands with Entropy -> [22, 58, 30, 21, 31, 172, 72, 40, 135, 132, 7, 44, 89, 13, 67, 71, 48, 62, 100, 19, 56, 113, 6, 116, 131]\n",
            "Top 25 bands with Entropy -> [125, 134, 141, 131, 171, 136, 139, 69, 101, 30, 80, 68, 33, 32, 90, 123, 166, 26, 172, 137, 37, 118, 158, 95, 7]\n",
            "Top 25 bands with Entropy -> [91, 139, 135, 19, 16, 97, 48, 77, 61, 49, 131, 84, 123, 60, 29, 28, 41, 69, 72, 9, 20, 162, 13, 24, 153]\n",
            "Top 25 bands with Entropy -> [115, 12, 40, 130, 93, 33, 129, 54, 8, 83, 91, 56, 118, 52, 57, 70, 132, 112, 148, 51, 37, 42, 41, 24, 61]\n",
            "Top 25 bands with Entropy -> [74, 23, 21, 43, 13, 173, 14, 123, 129, 65, 55, 96, 28, 25, 61, 98, 41, 112, 135, 67, 4, 132, 72, 125, 77]\n",
            "Top 25 bands with Entropy -> [61, 88, 25, 42, 99, 91, 63, 49, 58, 54, 100, 46, 89, 124, 8, 137, 158, 98, 51, 84, 64, 27, 77, 60, 26]\n",
            "Top 25 bands with Entropy -> [33, 65, 73, 126, 88, 53, 43, 18, 13, 136, 26, 92, 93, 118, 122, 89, 14, 25, 23, 49, 95, 125, 32, 115, 37]\n",
            "Top 25 bands with Entropy -> [113, 65, 75, 26, 125, 36, 137, 124, 45, 18, 32, 131, 37, 49, 8, 34, 158, 15, 132, 94, 19, 87, 77, 63, 99]\n",
            "Top 25 bands with Entropy -> [33, 14, 51, 21, 158, 27, 98, 13, 93, 88, 78, 71, 114, 41, 169, 127, 70, 113, 112, 36, 110, 162, 128, 139, 101]\n",
            "Top 25 bands with Entropy -> [20, 62, 130, 59, 46, 11, 34, 156, 108, 97, 22, 33, 131, 25, 45, 116, 141, 80, 44, 58, 55, 49, 96, 78, 171]\n",
            "Top 25 bands with Entropy -> [161, 52, 90, 113, 129, 64, 95, 62, 79, 98, 51, 81, 167, 54, 38, 14, 92, 75, 65, 100, 63, 141, 118, 153, 49]\n",
            "Top 25 bands with Entropy -> [58, 20, 73, 56, 86, 44, 18, 59, 12, 124, 115, 62, 81, 42, 74, 121, 37, 32, 54, 17, 160, 98, 6, 9, 48]\n",
            "Top 25 bands with Entropy -> [92, 56, 82, 95, 9, 71, 39, 80, 67, 30, 62, 87, 101, 127, 16, 19, 23, 26, 83, 75, 74, 21, 118, 2, 84]\n",
            "Top 25 bands with Entropy -> [96, 46, 83, 159, 47, 131, 172, 59, 36, 40, 92, 12, 29, 61, 164, 52, 56, 25, 113, 115, 67, 17, 75, 6, 97]\n",
            "Top 25 bands with Entropy -> [44, 48, 75, 108, 86, 154, 122, 19, 72, 114, 124, 15, 129, 42, 49, 51, 91, 136, 45, 24, 21, 55, 40, 113, 31]\n",
            "Top 25 bands with Entropy -> [62, 114, 82, 17, 89, 6, 83, 28, 99, 7, 11, 67, 58, 139, 135, 19, 75, 12, 131, 66, 117, 69, 120, 154, 38]\n",
            "Top 25 bands with Entropy -> [114, 75, 131, 78, 61, 72, 101, 73, 23, 134, 7, 15, 125, 38, 80, 128, 33, 94, 88, 55, 50, 28, 24, 168, 9]\n",
            "Top 25 bands with Entropy -> [166, 41, 40, 135, 174, 24, 132, 169, 80, 7, 6, 163, 34, 72, 28, 122, 78, 158, 148, 65, 26, 64, 44, 17, 58]\n",
            "Top 25 bands with Entropy -> [115, 51, 38, 127, 16, 63, 82, 57, 120, 78, 56, 39, 126, 124, 93, 27, 161, 42, 132, 6, 34, 17, 125, 95, 116]\n",
            "Top 25 bands with Entropy -> [26, 34, 10, 127, 91, 170, 124, 44, 35, 55, 11, 101, 59, 41, 62, 7, 5, 17, 18, 75, 85, 70, 131, 135, 61]\n",
            "Top 25 bands with Entropy -> [93, 7, 63, 26, 0, 77, 14, 174, 98, 15, 47, 74, 48, 54, 27, 95, 91, 72, 58, 43, 25, 82, 52, 36, 71]\n",
            "Top 25 bands with Entropy -> [8, 84, 125, 168, 161, 85, 64, 79, 137, 30, 16, 60, 128, 69, 37, 96, 3, 75, 12, 58, 49, 21, 31, 65, 10]\n",
            "Top 25 bands with Entropy -> [125, 3, 66, 65, 56, 52, 33, 100, 171, 46, 68, 2, 71, 127, 9, 36, 115, 97, 69, 15, 122, 62, 25, 88, 98]\n",
            "Top 25 bands with Entropy -> [119, 2, 22, 132, 81, 50, 120, 35, 20, 170, 15, 88, 13, 36, 33, 126, 95, 70, 98, 14, 6, 21, 63, 122, 40]\n",
            "Top 25 bands with Entropy -> [37, 89, 115, 129, 60, 70, 10, 30, 125, 48, 99, 67, 38, 34, 56, 86, 21, 68, 18, 27, 32, 46, 165, 95, 17]\n",
            "Top 25 bands with Entropy -> [136, 121, 65, 84, 68, 77, 70, 17, 89, 26, 10, 37, 35, 124, 28, 60, 93, 5, 115, 25, 11, 95, 51, 9, 58]\n",
            "Top 25 bands with Entropy -> [68, 136, 124, 49, 51, 67, 93, 41, 56, 69, 162, 131, 121, 17, 15, 132, 35, 80, 115, 39, 11, 135, 34, 13, 58]\n",
            "Top 25 bands with Entropy -> [81, 53, 13, 118, 136, 124, 122, 96, 5, 28, 54, 80, 87, 153, 9, 164, 51, 64, 63, 167, 117, 7, 94, 52, 66]\n",
            "Top 25 bands with Entropy -> [73, 80, 54, 113, 79, 58, 53, 83, 90, 16, 23, 98, 19, 95, 40, 13, 114, 48, 36, 82, 86, 43, 42, 61, 135]\n",
            "Top 25 bands with Entropy -> [40, 75, 32, 122, 69, 171, 49, 62, 73, 126, 154, 46, 175, 16, 125, 63, 78, 61, 79, 21, 98, 166, 5, 101, 135]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}